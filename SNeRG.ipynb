{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Preliminaries: Clone SNeRG repo"
      ],
      "metadata": {
        "id": "Ki19EiSby3vF"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kM_88u6AxTZ6",
        "outputId": "78fe00ca-36e2-40df-9b63-922629cde06f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fatal: destination path 'snerg' already exists and is not an empty directory.\n"
          ]
        }
      ],
      "source": [
        "# Clone SNeRG repository\n",
        "!git clone https://github.com/simicvm/snerg.git"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Install dependencies\n",
        "%%capture\n",
        "!pip install -r /content/snerg/requirements.txt"
      ],
      "metadata": {
        "id": "ypA6k4LXx4q7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Test whether install were successful\n",
        "!pip list | grep -q 'jaxlib' && echo 'Installation successful!'"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c4Uugx81ip68",
        "outputId": "64f529f6-1f75-415b-bd29-8cc3cf68b481"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ERROR: Pipe to stdout was broken\n",
            "Exception ignored in: <_io.TextIOWrapper name='<stdout>' mode='w' encoding='utf-8'>\n",
            "BrokenPipeError: [Errno 32] Broken pipe\n",
            "Installation successful!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Install Jaxlib for CUDA version"
      ],
      "metadata": {
        "id": "hiGIStm4zH9o"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!nvidia-smi"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M6mGcSn1zRGk",
        "outputId": "0db73463-90f2-4567-9d7e-09d68d98848a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sat Jul  1 17:56:44 2023       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 525.85.12    Driver Version: 525.85.12    CUDA Version: 12.0     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   44C    P8     9W /  70W |      0MiB / 15360MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install --upgrade jax[cuda12_pip]==0.4.6 jaxlib[cuda12_pip]==0.4.6 -f https://storage.googleapis.com/jax-releases/jax_cuda_releases.html"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZLYu1ufNzOs2",
        "outputId": "fd0aa01a-afcf-427c-f294-83fe57735fb3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in links: https://storage.googleapis.com/jax-releases/jax_cuda_releases.html\n",
            "Collecting jax[cuda12_pip]==0.4.6\n",
            "  Downloading jax-0.4.6.tar.gz (1.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m33.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting jaxlib[cuda12_pip]==0.4.6\n",
            "  Downloading https://storage.googleapis.com/jax-releases/cuda11/jaxlib-0.4.6%2Bcuda11.cudnn86-cp310-cp310-manylinux2014_x86_64.whl (147.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m147.6/147.6 MB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[33mWARNING: jax 0.4.6 does not provide the extra 'cuda12_pip'\u001b[0m\u001b[33m\n",
            "\u001b[0mRequirement already satisfied: numpy>=1.20 in /usr/local/lib/python3.10/dist-packages (from jax[cuda12_pip]==0.4.6) (1.22.4)\n",
            "Requirement already satisfied: opt_einsum in /usr/local/lib/python3.10/dist-packages (from jax[cuda12_pip]==0.4.6) (3.3.0)\n",
            "Requirement already satisfied: scipy>=1.5 in /usr/local/lib/python3.10/dist-packages (from jax[cuda12_pip]==0.4.6) (1.10.1)\n",
            "\u001b[33mWARNING: jaxlib 0.4.6+cuda11.cudnn86 does not provide the extra 'cuda12_pip'\u001b[0m\u001b[33m\n",
            "\u001b[0mBuilding wheels for collected packages: jax\n",
            "  Building wheel for jax (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for jax: filename=jax-0.4.6-py3-none-any.whl size=1432713 sha256=8b6f96b2ebadd2b5bdf5aaccbedc0d50c53e82fb1a37e80ac156de136b9e709c\n",
            "  Stored in directory: /root/.cache/pip/wheels/28/7e/d8/8d95ab71cec5f4ad4df8da6d4787e049a97ddf5125b8814bb3\n",
            "Successfully built jax\n",
            "Installing collected packages: jaxlib, jax\n",
            "  Attempting uninstall: jaxlib\n",
            "    Found existing installation: jaxlib 0.4.10+cuda11.cudnn86\n",
            "    Uninstalling jaxlib-0.4.10+cuda11.cudnn86:\n",
            "      Successfully uninstalled jaxlib-0.4.10+cuda11.cudnn86\n",
            "  Attempting uninstall: jax\n",
            "    Found existing installation: jax 0.4.10\n",
            "    Uninstalling jax-0.4.10:\n",
            "      Successfully uninstalled jax-0.4.10\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "orbax-checkpoint 0.2.6 requires jax>=0.4.9, but you have jax 0.4.6 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed jax-0.4.6 jaxlib-0.4.6+cuda11.cudnn86\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Unzip Dataset\n",
        "\n",
        "Run the `estimate_camera_poses.py` from the `COLMAP` library and zip the resulting dataset folder (e.g. `room`). Then upload the zip file and unzip;"
      ],
      "metadata": {
        "id": "14Y5Fi0YjXAF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "DATASET_FILE = '/content/nerf_datasets.zip'"
      ],
      "metadata": {
        "id": "dfw5hIBMkLMl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%capture\n",
        "!unzip $DATASET_FILE -d /content"
      ],
      "metadata": {
        "id": "nkB7S9DEjuAs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Run SNeRG\n",
        "\n",
        "If you run out of memory, modify `snerg/configs/llff.yaml` with the following lines:\n",
        "\n",
        "`voxel_resolution: 800`<br>\n",
        "`batch_size: 256`<br>\n",
        "`snerg_dtype: float16`\n"
      ],
      "metadata": {
        "id": "xAkFE6MW1Wp2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!cd snerg; python -m train \\\n",
        "  --data_dir=/content/nerf_datasets/room \\\n",
        "  --train_dir=/content/checkpoints \\\n",
        "  --config=/content/snerg/configs/llff"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OHLbwJcg1aaT",
        "outputId": "6ae287a8-88f5-493c-9e6d-e93e5fdc940c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/flax/struct.py:132: FutureWarning: jax.tree_util.register_keypaths is deprecated, and will be removed in a future release. Please use `register_pytree_with_keys()` instead.\n",
            "  jax.tree_util.register_keypaths(data_clz, keypaths)\n",
            "/usr/local/lib/python3.10/dist-packages/flax/struct.py:132: FutureWarning: jax.tree_util.register_keypaths is deprecated, and will be removed in a future release. Please use `register_pytree_with_keys()` instead.\n",
            "  jax.tree_util.register_keypaths(data_clz, keypaths)\n",
            "2023-07-01 18:01:29.251788: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "/usr/local/lib/python3.10/dist-packages/flax/struct.py:132: FutureWarning: jax.tree_util.register_keypaths is deprecated, and will be removed in a future release. Please use `register_pytree_with_keys()` instead.\n",
            "  jax.tree_util.register_keypaths(data_clz, keypaths)\n",
            "I0701 18:01:32.141833 140253304252224 xla_bridge.py:166] Remote TPU is not linked into jax; skipping remote TPU.\n",
            "I0701 18:01:32.142035 140253304252224 xla_bridge.py:413] Unable to initialize backend 'tpu_driver': Could not initialize backend 'tpu_driver'\n",
            "I0701 18:01:32.244272 140253304252224 xla_bridge.py:413] Unable to initialize backend 'rocm': NOT_FOUND: Could not find registered platform with name: \"rocm\". Available platform names are: Interpreter CUDA Host\n",
            "I0701 18:01:32.244774 140253304252224 xla_bridge.py:413] Unable to initialize backend 'tpu': module 'jaxlib.xla_extension' has no attribute 'get_tpu_client'\n",
            "I0701 18:01:32.244904 140253304252224 xla_bridge.py:413] Unable to initialize backend 'plugin': xla_extension has no attributes named get_plugin_device_client. Compile TensorFlow with //tensorflow/compiler/xla/python:enable_plugin_device set to true (defaults to false) to enable this.\n",
            "/usr/local/lib/python3.10/dist-packages/jax/_src/xla_bridge.py:600: UserWarning: jax.host_id has been renamed to jax.process_index. This alias will eventually be removed; please update your code.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/jax/_src/xla_bridge.py:613: UserWarning: jax.host_count has been renamed to jax.process_count. This alias will eventually be removed; please update your code.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/flax/optim/base.py:49: DeprecationWarning: Use `optax` instead of `flax.optim`. Refer to the update guide https://flax.readthedocs.io/en/latest/howtos/optax_update_guide.html for detailed instructions.\n",
            "  warnings.warn(\n",
            "I0701 18:02:28.578345 140253304252224 checkpoints.py:425] Found no checkpoint files in /content/checkpoints with prefix checkpoint_\n",
            "/usr/local/lib/python3.10/dist-packages/jax/_src/xla_bridge.py:600: UserWarning: jax.host_id has been renamed to jax.process_index. This alias will eventually be removed; please update your code.\n",
            "  warnings.warn(\n",
            "2023-07-01 18:02:28.696097: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:47] Overriding orig_value setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
            "/usr/local/lib/python3.10/dist-packages/flax/optim/base.py:90: FutureWarning: jax.tree_flatten is deprecated, and will be removed in a future release. Use jax.tree_util.tree_flatten instead.\n",
            "  params_flat, treedef = jax.tree_flatten(params)\n",
            "/usr/local/lib/python3.10/dist-packages/flax/optim/base.py:97: FutureWarning: jax.tree_unflatten is deprecated, and will be removed in a future release. Use jax.tree_util.tree_unflatten instead.\n",
            "  new_params = jax.tree_unflatten(treedef, new_params_flat)\n",
            "/usr/local/lib/python3.10/dist-packages/flax/optim/base.py:98: FutureWarning: jax.tree_unflatten is deprecated, and will be removed in a future release. Use jax.tree_util.tree_unflatten instead.\n",
            "  new_param_states = jax.tree_unflatten(treedef, new_states_flat)\n",
            "/usr/local/lib/python3.10/dist-packages/jax/_src/interpreters/mlir.py:711: UserWarning: Some donated buffers were not usable: ShapedArray(float32[256,3]), ShapedArray(float32[256,3]), ShapedArray(float32[256,3]), ShapedArray(float32[256,3]).\n",
            "See an explanation at https://jax.readthedocs.io/en/latest/faq.html#buffer-donation.\n",
            "  warnings.warn(f\"Some donated buffers were not usable: {', '.join(unused_donations)}.\\n{msg}\")\n",
            "  100/10000: i_loss=0.1639, avg_loss=0.3067, weight_l2=8.02e-03, lr=3.74e-05, 975 rays/sec\n",
            "  200/10000: i_loss=0.0683, avg_loss=0.0868, weight_l2=8.06e-03, lr=4.85e-05, 3145 rays/sec\n",
            "  300/10000: i_loss=0.0654, avg_loss=0.0603, weight_l2=8.07e-03, lr=5.85e-05, 3132 rays/sec\n",
            "  400/10000: i_loss=0.0484, avg_loss=0.0533, weight_l2=8.07e-03, lr=6.73e-05, 3117 rays/sec\n",
            "  500/10000: i_loss=0.0429, avg_loss=0.0465, weight_l2=8.07e-03, lr=7.51e-05, 3078 rays/sec\n",
            "  600/10000: i_loss=0.0406, avg_loss=0.0391, weight_l2=8.08e-03, lr=8.18e-05, 3053 rays/sec\n",
            "  700/10000: i_loss=0.0377, avg_loss=0.0347, weight_l2=8.09e-03, lr=8.75e-05, 3032 rays/sec\n",
            "  800/10000: i_loss=0.0306, avg_loss=0.0311, weight_l2=8.10e-03, lr=9.23e-05, 3057 rays/sec\n",
            "  900/10000: i_loss=0.0262, avg_loss=0.0285, weight_l2=8.12e-03, lr=9.62e-05, 3100 rays/sec\n",
            " 1000/10000: i_loss=0.0238, avg_loss=0.0260, weight_l2=8.13e-03, lr=9.92e-05, 3145 rays/sec\n",
            " 1100/10000: i_loss=0.0218, avg_loss=0.0235, weight_l2=8.14e-03, lr=1.01e-04, 3127 rays/sec\n",
            " 1200/10000: i_loss=0.0229, avg_loss=0.0235, weight_l2=8.15e-03, lr=1.03e-04, 3144 rays/sec\n",
            "/usr/local/lib/python3.10/dist-packages/jax/_src/xla_bridge.py:613: UserWarning: jax.host_count has been renamed to jax.process_count. This alias will eventually be removed; please update your code.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/jax/_src/interpreters/mlir.py:711: UserWarning: Some donated buffers were not usable: ShapedArray(float32[512,3]), ShapedArray(float32[512,3]), ShapedArray(float32[512,3]).\n",
            "See an explanation at https://jax.readthedocs.io/en/latest/faq.html#buffer-donation.\n",
            "  warnings.warn(f\"Some donated buffers were not usable: {', '.join(unused_donations)}.\\n{msg}\")\n",
            "/usr/local/lib/python3.10/dist-packages/jax/_src/interpreters/mlir.py:711: UserWarning: Some donated buffers were not usable: ShapedArray(float32[192,3]), ShapedArray(float32[192,3]), ShapedArray(float32[192,3]).\n",
            "See an explanation at https://jax.readthedocs.io/en/latest/faq.html#buffer-donation.\n",
            "  warnings.warn(f\"Some donated buffers were not usable: {', '.join(unused_donations)}.\\n{msg}\")\n",
            "Eval 1200: 107.349s., 7099 rays/sec\n",
            " 1300/10000: i_loss=0.0187, avg_loss=0.0228, weight_l2=8.16e-03, lr=1.04e-04, 3129 rays/sec\n",
            " 1400/10000: i_loss=0.0206, avg_loss=0.0222, weight_l2=8.17e-03, lr=1.04e-04, 3142 rays/sec\n",
            " 1500/10000: i_loss=0.0194, avg_loss=0.0212, weight_l2=8.18e-03, lr=1.04e-04, 3117 rays/sec\n",
            " 1600/10000: i_loss=0.0215, avg_loss=0.0212, weight_l2=8.19e-03, lr=1.03e-04, 3090 rays/sec\n",
            " 1700/10000: i_loss=0.0200, avg_loss=0.0210, weight_l2=8.19e-03, lr=1.02e-04, 3124 rays/sec\n",
            " 1800/10000: i_loss=0.0192, avg_loss=0.0207, weight_l2=8.20e-03, lr=9.98e-05, 3142 rays/sec\n",
            " 1900/10000: i_loss=0.0169, avg_loss=0.0201, weight_l2=8.21e-03, lr=9.76e-05, 3131 rays/sec\n",
            " 2000/10000: i_loss=0.0239, avg_loss=0.0204, weight_l2=8.21e-03, lr=9.51e-05, 3148 rays/sec\n",
            " 2100/10000: i_loss=0.0157, avg_loss=0.0196, weight_l2=8.22e-03, lr=9.24e-05, 3140 rays/sec\n",
            " 2200/10000: i_loss=0.0187, avg_loss=0.0198, weight_l2=8.22e-03, lr=8.93e-05, 3149 rays/sec\n",
            " 2300/10000: i_loss=0.0234, avg_loss=0.0199, weight_l2=8.23e-03, lr=8.61e-05, 3143 rays/sec\n",
            " 2400/10000: i_loss=0.0191, avg_loss=0.0197, weight_l2=8.23e-03, lr=8.26e-05, 3129 rays/sec\n",
            "Eval 2400: 94.786s., 8040 rays/sec\n",
            " 2500/10000: i_loss=0.0201, avg_loss=0.0193, weight_l2=8.23e-03, lr=7.91e-05, 3120 rays/sec\n",
            "I0701 18:09:38.915729 140253304252224 checkpoints.py:317] Saving checkpoint at step: 2500\n",
            "I0701 18:09:38.930159 140253304252224 checkpoints.py:278] Saved checkpoint at /content/checkpoints/checkpoint_2500\n",
            " 2600/10000: i_loss=0.0128, avg_loss=0.0190, weight_l2=8.24e-03, lr=7.55e-05, 3138 rays/sec\n",
            " 2700/10000: i_loss=0.0207, avg_loss=0.0185, weight_l2=8.24e-03, lr=7.21e-05, 3129 rays/sec\n",
            " 2800/10000: i_loss=0.0176, avg_loss=0.0192, weight_l2=8.25e-03, lr=6.89e-05, 3117 rays/sec\n",
            " 2900/10000: i_loss=0.0173, avg_loss=0.0190, weight_l2=8.25e-03, lr=6.58e-05, 3121 rays/sec\n",
            " 3000/10000: i_loss=0.0141, avg_loss=0.0189, weight_l2=8.25e-03, lr=6.28e-05, 3138 rays/sec\n",
            " 3100/10000: i_loss=0.0235, avg_loss=0.0187, weight_l2=8.26e-03, lr=6.00e-05, 3142 rays/sec\n",
            " 3200/10000: i_loss=0.0189, avg_loss=0.0185, weight_l2=8.26e-03, lr=5.73e-05, 3128 rays/sec\n",
            " 3300/10000: i_loss=0.0165, avg_loss=0.0184, weight_l2=8.26e-03, lr=5.47e-05, 3139 rays/sec\n",
            " 3400/10000: i_loss=0.0181, avg_loss=0.0182, weight_l2=8.26e-03, lr=5.22e-05, 3135 rays/sec\n",
            " 3500/10000: i_loss=0.0192, avg_loss=0.0187, weight_l2=8.27e-03, lr=4.99e-05, 3134 rays/sec\n",
            " 3600/10000: i_loss=0.0191, avg_loss=0.0178, weight_l2=8.27e-03, lr=4.76e-05, 3134 rays/sec\n",
            "Eval 3600: 96.317s., 7912 rays/sec\n",
            " 3700/10000: i_loss=0.0164, avg_loss=0.0184, weight_l2=8.27e-03, lr=4.55e-05, 3108 rays/sec\n",
            " 3800/10000: i_loss=0.0192, avg_loss=0.0178, weight_l2=8.27e-03, lr=4.34e-05, 3132 rays/sec\n",
            " 3900/10000: i_loss=0.0180, avg_loss=0.0184, weight_l2=8.28e-03, lr=4.15e-05, 3122 rays/sec\n",
            " 4000/10000: i_loss=0.0154, avg_loss=0.0182, weight_l2=8.28e-03, lr=3.96e-05, 3118 rays/sec\n",
            " 4100/10000: i_loss=0.0216, avg_loss=0.0182, weight_l2=8.28e-03, lr=3.78e-05, 3132 rays/sec\n",
            " 4200/10000: i_loss=0.0173, avg_loss=0.0180, weight_l2=8.28e-03, lr=3.61e-05, 3131 rays/sec\n",
            " 4300/10000: i_loss=0.0153, avg_loss=0.0175, weight_l2=8.28e-03, lr=3.45e-05, 3134 rays/sec\n",
            " 4400/10000: i_loss=0.0178, avg_loss=0.0180, weight_l2=8.29e-03, lr=3.30e-05, 3142 rays/sec\n",
            " 4500/10000: i_loss=0.0183, avg_loss=0.0183, weight_l2=8.29e-03, lr=3.15e-05, 3130 rays/sec\n",
            " 4600/10000: i_loss=0.0197, avg_loss=0.0178, weight_l2=8.29e-03, lr=3.01e-05, 3142 rays/sec\n",
            " 4700/10000: i_loss=0.0154, avg_loss=0.0178, weight_l2=8.29e-03, lr=2.87e-05, 3134 rays/sec\n",
            " 4800/10000: i_loss=0.0166, avg_loss=0.0181, weight_l2=8.29e-03, lr=2.74e-05, 3142 rays/sec\n",
            "Eval 4800: 94.879s., 8032 rays/sec\n",
            " 4900/10000: i_loss=0.0177, avg_loss=0.0174, weight_l2=8.29e-03, lr=2.62e-05, 3124 rays/sec\n",
            " 5000/10000: i_loss=0.0170, avg_loss=0.0174, weight_l2=8.30e-03, lr=2.50e-05, 3090 rays/sec\n",
            "I0701 18:16:18.701954 140253304252224 checkpoints.py:317] Saving checkpoint at step: 5000\n",
            "I0701 18:16:18.720589 140253304252224 checkpoints.py:278] Saved checkpoint at /content/checkpoints/checkpoint_5000\n",
            " 5100/10000: i_loss=0.0181, avg_loss=0.0175, weight_l2=8.30e-03, lr=2.39e-05, 3120 rays/sec\n",
            " 5200/10000: i_loss=0.0149, avg_loss=0.0170, weight_l2=8.30e-03, lr=2.28e-05, 3131 rays/sec\n",
            " 5300/10000: i_loss=0.0179, avg_loss=0.0181, weight_l2=8.30e-03, lr=2.18e-05, 3130 rays/sec\n",
            " 5400/10000: i_loss=0.0252, avg_loss=0.0182, weight_l2=8.30e-03, lr=2.08e-05, 3129 rays/sec\n",
            " 5500/10000: i_loss=0.0183, avg_loss=0.0178, weight_l2=8.30e-03, lr=1.99e-05, 3134 rays/sec\n",
            " 5600/10000: i_loss=0.0193, avg_loss=0.0176, weight_l2=8.30e-03, lr=1.90e-05, 3140 rays/sec\n",
            " 5700/10000: i_loss=0.0182, avg_loss=0.0171, weight_l2=8.30e-03, lr=1.81e-05, 3145 rays/sec\n",
            " 5800/10000: i_loss=0.0140, avg_loss=0.0170, weight_l2=8.30e-03, lr=1.73e-05, 3132 rays/sec\n",
            " 5900/10000: i_loss=0.0161, avg_loss=0.0171, weight_l2=8.31e-03, lr=1.65e-05, 3137 rays/sec\n",
            " 6000/10000: i_loss=0.0212, avg_loss=0.0179, weight_l2=8.31e-03, lr=1.58e-05, 3142 rays/sec\n",
            "Eval 6000: 96.343s., 7910 rays/sec\n",
            " 6100/10000: i_loss=0.0220, avg_loss=0.0175, weight_l2=8.31e-03, lr=1.51e-05, 3116 rays/sec\n",
            " 6200/10000: i_loss=0.0180, avg_loss=0.0175, weight_l2=8.31e-03, lr=1.44e-05, 3138 rays/sec\n",
            " 6300/10000: i_loss=0.0217, avg_loss=0.0172, weight_l2=8.31e-03, lr=1.37e-05, 3116 rays/sec\n",
            " 6400/10000: i_loss=0.0190, avg_loss=0.0172, weight_l2=8.31e-03, lr=1.31e-05, 3103 rays/sec\n",
            " 6500/10000: i_loss=0.0177, avg_loss=0.0177, weight_l2=8.31e-03, lr=1.25e-05, 3132 rays/sec\n",
            " 6600/10000: i_loss=0.0168, avg_loss=0.0175, weight_l2=8.31e-03, lr=1.20e-05, 3127 rays/sec\n",
            " 6700/10000: i_loss=0.0167, avg_loss=0.0174, weight_l2=8.31e-03, lr=1.14e-05, 3132 rays/sec\n",
            " 6800/10000: i_loss=0.0142, avg_loss=0.0175, weight_l2=8.31e-03, lr=1.09e-05, 3138 rays/sec\n",
            " 6900/10000: i_loss=0.0151, avg_loss=0.0173, weight_l2=8.31e-03, lr=1.04e-05, 3136 rays/sec\n",
            " 7000/10000: i_loss=0.0118, avg_loss=0.0173, weight_l2=8.31e-03, lr=9.95e-06, 3146 rays/sec\n",
            " 7100/10000: i_loss=0.0246, avg_loss=0.0171, weight_l2=8.31e-03, lr=9.50e-06, 3123 rays/sec\n",
            " 7200/10000: i_loss=0.0245, avg_loss=0.0172, weight_l2=8.31e-03, lr=9.08e-06, 3143 rays/sec\n",
            "Eval 7200: 95.125s., 8011 rays/sec\n",
            " 7300/10000: i_loss=0.0183, avg_loss=0.0174, weight_l2=8.31e-03, lr=8.67e-06, 3122 rays/sec\n",
            " 7400/10000: i_loss=0.0177, avg_loss=0.0176, weight_l2=8.31e-03, lr=8.28e-06, 3130 rays/sec\n",
            " 7500/10000: i_loss=0.0167, avg_loss=0.0172, weight_l2=8.32e-03, lr=7.91e-06, 3134 rays/sec\n",
            "I0701 18:22:58.700915 140253304252224 checkpoints.py:317] Saving checkpoint at step: 7500\n",
            "I0701 18:22:58.711136 140253304252224 checkpoints.py:278] Saved checkpoint at /content/checkpoints/checkpoint_7500\n",
            " 7600/10000: i_loss=0.0182, avg_loss=0.0174, weight_l2=8.32e-03, lr=7.55e-06, 3139 rays/sec\n",
            " 7700/10000: i_loss=0.0188, avg_loss=0.0176, weight_l2=8.32e-03, lr=7.21e-06, 3136 rays/sec\n",
            " 7800/10000: i_loss=0.0150, avg_loss=0.0172, weight_l2=8.32e-03, lr=6.89e-06, 3140 rays/sec\n",
            " 7900/10000: i_loss=0.0209, avg_loss=0.0173, weight_l2=8.32e-03, lr=6.58e-06, 3138 rays/sec\n",
            " 8000/10000: i_loss=0.0145, avg_loss=0.0171, weight_l2=8.32e-03, lr=6.28e-06, 3114 rays/sec\n",
            " 8100/10000: i_loss=0.0184, avg_loss=0.0173, weight_l2=8.32e-03, lr=6.00e-06, 3142 rays/sec\n",
            " 8200/10000: i_loss=0.0242, avg_loss=0.0172, weight_l2=8.32e-03, lr=5.73e-06, 3144 rays/sec\n",
            " 8300/10000: i_loss=0.0197, avg_loss=0.0178, weight_l2=8.32e-03, lr=5.47e-06, 3145 rays/sec\n",
            " 8400/10000: i_loss=0.0161, avg_loss=0.0175, weight_l2=8.32e-03, lr=5.22e-06, 3123 rays/sec\n",
            "Eval 8400: 94.704s., 8047 rays/sec\n",
            " 8500/10000: i_loss=0.0186, avg_loss=0.0170, weight_l2=8.32e-03, lr=4.99e-06, 3127 rays/sec\n",
            " 8600/10000: i_loss=0.0180, avg_loss=0.0169, weight_l2=8.32e-03, lr=4.76e-06, 3138 rays/sec\n",
            " 8700/10000: i_loss=0.0165, avg_loss=0.0170, weight_l2=8.32e-03, lr=4.55e-06, 3128 rays/sec\n",
            " 8800/10000: i_loss=0.0155, avg_loss=0.0176, weight_l2=8.32e-03, lr=4.34e-06, 3115 rays/sec\n",
            " 8900/10000: i_loss=0.0212, avg_loss=0.0174, weight_l2=8.32e-03, lr=4.15e-06, 3135 rays/sec\n",
            " 9000/10000: i_loss=0.0172, avg_loss=0.0170, weight_l2=8.32e-03, lr=3.96e-06, 3137 rays/sec\n",
            " 9100/10000: i_loss=0.0179, avg_loss=0.0174, weight_l2=8.32e-03, lr=3.78e-06, 3135 rays/sec\n",
            " 9200/10000: i_loss=0.0191, avg_loss=0.0171, weight_l2=8.32e-03, lr=3.61e-06, 3128 rays/sec\n",
            " 9300/10000: i_loss=0.0132, avg_loss=0.0170, weight_l2=8.32e-03, lr=3.45e-06, 3141 rays/sec\n",
            " 9400/10000: i_loss=0.0162, avg_loss=0.0173, weight_l2=8.32e-03, lr=3.30e-06, 3138 rays/sec\n",
            " 9500/10000: i_loss=0.0175, avg_loss=0.0168, weight_l2=8.32e-03, lr=3.15e-06, 3135 rays/sec\n",
            " 9600/10000: i_loss=0.0160, avg_loss=0.0174, weight_l2=8.32e-03, lr=3.01e-06, 3143 rays/sec\n",
            "Eval 9600: 95.776s., 7957 rays/sec\n",
            " 9700/10000: i_loss=0.0181, avg_loss=0.0171, weight_l2=8.32e-03, lr=2.87e-06, 3125 rays/sec\n",
            " 9800/10000: i_loss=0.0116, avg_loss=0.0174, weight_l2=8.32e-03, lr=2.74e-06, 3138 rays/sec\n",
            " 9900/10000: i_loss=0.0126, avg_loss=0.0171, weight_l2=8.32e-03, lr=2.62e-06, 3121 rays/sec\n",
            "10000/10000: i_loss=0.0170, avg_loss=0.0171, weight_l2=8.32e-03, lr=2.50e-06, 3054 rays/sec\n",
            "I0701 18:29:38.358525 140253304252224 checkpoints.py:317] Saving checkpoint at step: 10000\n",
            "I0701 18:29:38.373839 140253304252224 checkpoints.py:278] Saved checkpoint at /content/checkpoints/checkpoint_10000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!cd snerg; python -m bake \\\n",
        "  --data_dir=/content/nerf_datasets/room \\\n",
        "  --train_dir=/content/checkpoints \\\n",
        "  --config=configs/llff"
      ],
      "metadata": {
        "id": "Us5axqpsmurl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a832c27e-cd28-4477-eb4c-255de902ada0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/flax/struct.py:132: FutureWarning: jax.tree_util.register_keypaths is deprecated, and will be removed in a future release. Please use `register_pytree_with_keys()` instead.\n",
            "  jax.tree_util.register_keypaths(data_clz, keypaths)\n",
            "/usr/local/lib/python3.10/dist-packages/flax/struct.py:132: FutureWarning: jax.tree_util.register_keypaths is deprecated, and will be removed in a future release. Please use `register_pytree_with_keys()` instead.\n",
            "  jax.tree_util.register_keypaths(data_clz, keypaths)\n",
            "2023-07-01 18:48:48.775498: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "/usr/local/lib/python3.10/dist-packages/flax/struct.py:132: FutureWarning: jax.tree_util.register_keypaths is deprecated, and will be removed in a future release. Please use `register_pytree_with_keys()` instead.\n",
            "  jax.tree_util.register_keypaths(data_clz, keypaths)\n",
            "I0701 18:48:52.383014 139947824318272 xla_bridge.py:166] Remote TPU is not linked into jax; skipping remote TPU.\n",
            "I0701 18:48:52.383214 139947824318272 xla_bridge.py:413] Unable to initialize backend 'tpu_driver': Could not initialize backend 'tpu_driver'\n",
            "I0701 18:48:52.484800 139947824318272 xla_bridge.py:413] Unable to initialize backend 'rocm': NOT_FOUND: Could not find registered platform with name: \"rocm\". Available platform names are: Interpreter Host CUDA\n",
            "I0701 18:48:52.485272 139947824318272 xla_bridge.py:413] Unable to initialize backend 'tpu': module 'jaxlib.xla_extension' has no attribute 'get_tpu_client'\n",
            "I0701 18:48:52.485400 139947824318272 xla_bridge.py:413] Unable to initialize backend 'plugin': xla_extension has no attributes named get_plugin_device_client. Compile TensorFlow with //tensorflow/compiler/xla/python:enable_plugin_device set to true (defaults to false) to enable this.\n",
            "/usr/local/lib/python3.10/dist-packages/jax/_src/xla_bridge.py:613: UserWarning: jax.host_count has been renamed to jax.process_count. This alias will eventually be removed; please update your code.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/flax/optim/base.py:49: DeprecationWarning: Use `optax` instead of `flax.optim`. Refer to the update guide https://flax.readthedocs.io/en/latest/howtos/optax_update_guide.html for detailed instructions.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/jax/_src/xla_bridge.py:600: UserWarning: jax.host_id has been renamed to jax.process_index. This alias will eventually be removed; please update your code.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/jax/_src/xla_bridge.py:613: UserWarning: jax.host_count has been renamed to jax.process_count. This alias will eventually be removed; please update your code.\n",
            "  warnings.warn(\n",
            "I0701 18:49:53.200719 139947824318272 checkpoints.py:429] Restoring checkpoint from /content/checkpoints/checkpoint_10000\n",
            "10000\n",
            "/usr/local/lib/python3.10/dist-packages/numpy/core/fromnumeric.py:57: RuntimeWarning: overflow encountered in accumulate\n",
            "  return bound(*args, **kwds)\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n",
            "    return _run_code(code, main_globals, None,\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 86, in _run_code\n",
            "    exec(code, run_globals)\n",
            "  File \"/content/snerg/bake.py\", line 327, in <module>\n",
            "    app.run(main)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/absl/app.py\", line 308, in run\n",
            "    _run_main(main, args)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/absl/app.py\", line 254, in _run_main\n",
            "    sys.exit(main(argv))\n",
            "  File \"/content/snerg/bake.py\", line 177, in main\n",
            "    atlas, atlas_block_indices = baking.extract_3d_atlas(\n",
            "  File \"/content/snerg/snerg/baking.py\", line 239, in extract_3d_atlas\n",
            "    atlas_rgb, atlas_alpha = render_voxel_block(\n",
            "  File \"/content/snerg/snerg/baking.py\", line 87, in render_voxel_block\n",
            "    origins = block_coordinates_world.reshape((-1, 3)).copy()\n",
            "KeyboardInterrupt\n",
            "^C\n"
          ]
        }
      ]
    }
  ]
}